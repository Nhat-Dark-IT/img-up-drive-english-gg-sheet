# src/main.py
import os
import sys
import time
from datetime import datetime
import schedule
import logging
# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from config.settings import SCHEDULE_TIMES
from src.drive_handler import DriveHandler
from src.image_processor import ImageProcessor
from src.sheets_handler import SheetsHandler

class VocabularyAutomation:
    def __init__(self):
        """Kh·ªüi t·∫°o c√°c components."""
        self.drive = DriveHandler()
        self.processor = ImageProcessor()
        self.sheets = SheetsHandler()
        
    def process_folder(self, folder_type):
        """X·ª≠ l√Ω m·ªôt th∆∞ m·ª•c t·ª´ v·ª±ng."""
        temp_files = []  # Track all temporary files
        
        try:
            print(f"\nProcessing {folder_type} folder...")
            
            # 1. L·∫•y ID th∆∞ m·ª•c g·ªëc
            folder_id = self.drive.get_folder_id(folder_type)
            if not folder_id:
                print(f"Folder not found for type: {folder_type}")
                return
                
            # 2. T·∫°o/l·∫•y th∆∞ m·ª•c ng√†y
            date_folder_id = self.drive.create_date_folder(folder_id)
            
            # 3. L·∫•y danh s√°ch ·∫£nh
            images = self.drive.list_images(date_folder_id)
            if not images:
                print("No images found to process")
                return
            # L·ªçc ·∫£nh ch∆∞a x·ª≠ l√Ω
            unprocessed_images = [
                img for img in images 
                if not img['name'].startswith('DONE_')
            ]
            
            if not unprocessed_images:
                print("All images have been processed")
                return
                
            print(f"Found {len(unprocessed_images)} unprocessed images")
            # 4. X·ª≠ l√Ω t·ª´ng ·∫£nh v√† thu th·∫≠p data
            vocabulary_data = []
            for image in unprocessed_images:
                try:
                    # Download ·∫£nh
                    temp_path = os.path.join("temp", image['name'])
                    os.makedirs("temp", exist_ok=True)
                    self.drive.download_image(image['id'], temp_path)
                    # Add paths to cleanup list
                    processed_path = temp_path.replace('.jpg', '_processed.jpg')
                    enhanced_path = temp_path.replace('.jpg', '_processed_enhanced.txt')
                    ocr_path = temp_path.replace('.jpg', '_processed_ocr.txt')
                    
                    temp_files.extend([
                        temp_path,
                        processed_path,
                        enhanced_path,
                        ocr_path
                    ])
                    # X·ª≠ l√Ω OCR v√† AI
                    enhanced_text = self.processor.process_image(temp_path, processed_path)
                    
                    # Parse k·∫øt qu·∫£ t·ª´ file enhanced
                    entries = self.parse_vocabulary(image['name'], enhanced_text)
                    if entries:
                        vocabulary_data.extend(entries)
                        print(f"Found {len(entries)} entries from {image['name']}")
                    
                    # ƒê√°nh d·∫•u ƒë√£ x·ª≠ l√Ω
                    processed_name = f"DONE_{image['name']}"
                    self.drive.mark_as_processed(image['id'], processed_name)
                    # Th√™m file v√†o danh s√°ch c·∫ßn x√≥a sau khi l∆∞u v√†o Google Sheets
                    # Cleanup
                    os.remove(temp_path)
                    if os.path.exists(processed_path):
                        os.remove(processed_path)
                     
                except Exception as e:
                    print(f"Error processing image {image['name']}: {str(e)}")
                    continue
            
            # 5. Append t·∫•t c·∫£ data v√†o sheet
            if vocabulary_data:
                self.sheets.append_vocabulary(folder_type, vocabulary_data)
                print(f"\n‚úÖ Successfully added {len(vocabulary_data)} total entries to {folder_type} sheet")
            else:
                print(f"\nNo entries found to add to {folder_type} sheet")
                
        except Exception as e:
            print(f"Error processing folder {folder_type}: {str(e)}")
            
        finally:
            # Cleanup all temporary files
            print("\nCleaning up temporary files...")
            for file_path in temp_files:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        print(f"üóëÔ∏è Deleted: {file_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error deleting file {file_path}: {str(e)}")
            
    
    def parse_vocabulary(self, image_name, enhanced_text):
        """Parse k·∫øt qu·∫£ t·ª´ file enhanced text."""
        try:
            # L·∫•y ƒë∆∞·ªùng d·∫´n file enhanced text
            enhanced_path = image_name.replace('.jpg', '_processed_enhanced.txt')
            enhanced_path = os.path.join('temp', enhanced_path)
            
            # Ki·ªÉm tra file t·ªìn t·∫°i
            if not os.path.exists(enhanced_path):
                print(f"‚ö†Ô∏è Enhanced text file not found: {enhanced_path}")
                return None
                
            # ƒê·ªçc n·ªôi dung file
            with open(enhanced_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
            # Parse t·ª´ng d√≤ng th√†nh entries
            vocab_entries = []
            for line in lines:
                if not line.strip():
                    continue
                    
                # Split by tab
                parts = line.strip().split('\t')
                
                # ƒê·∫£m b·∫£o ƒë·ªß 4 ph·∫ßn t·ª≠
                while len(parts) < 4:
                    parts.append('')
                    
                # Create entry v·ªõi c√°c tr∆∞·ªùng m·∫∑c ƒë·ªãnh n·∫øu thi·∫øu
                entry = {
                    'image_name': image_name,
                    'title': parts[0].strip() or 'Undefined',  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu tr·ªëng
                    'word': parts[1].strip() or 'Unknown',     # Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu tr·ªëng
                    'vn_meaning': parts[2].strip() or 'Ch∆∞a c√≥ nghƒ©a',  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu tr·ªëng
                    'en_meaning': parts[3].strip() or 'No meaning'      # Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu tr·ªëng
                }
                
                # Log warning n·∫øu thi·∫øu th√¥ng tin
                missing_fields = []
                if not parts[1].strip(): missing_fields.append('word')
                if not parts[2].strip(): missing_fields.append('vn_meaning') 
                if not parts[3].strip(): missing_fields.append('en_meaning')
                
                if missing_fields:
                    print(f"‚ö†Ô∏è Missing fields {missing_fields} in entry: {line}")
                
                vocab_entries.append(entry)
                    
            return vocab_entries if vocab_entries else None
            
        except Exception as e:
            print(f"‚ùå Error parsing vocabulary: {str(e)}")
            return None
    
    def run_job(self):
        """Ch·∫°y x·ª≠ l√Ω t·∫•t c·∫£ lo·∫°i th∆∞ m·ª•c."""
        print(f"\nRunning automation job at {datetime.now()}")
        
        folder_types = ['daily', 'synonyms', 'toeic', 'ielts']
        for folder_type in folder_types:
            self.process_folder(folder_type)
            
def main():
    logging.info("Starting vocabulary automation...")
    """Main function ƒë·ªÉ ch·∫°y automation."""
    automation = VocabularyAutomation()
    
    # Ch·∫°y l·∫ßn ƒë·∫ßu
    automation.run_job()   
    # Keep running

if __name__ == "__main__":
    main()
    